{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMkAgYc8MuCq"
      },
      "source": [
        "# **Keyword Spotting Dataset Curation**\n",
        "\n",
        "[![Open In Colab <](https://colab.research.google.com/assets/colab-badge.svg)]()\n",
        "\n",
        "***We will use colab to download the Google Speech Commands Dataset, mix in some background noise, and upload the curated dataset to Edge Impulse. From there, we can train a neural network to classify spoken words and upload it to a microcontroller to perform real-time keyword spotting.***\n",
        "\n",
        "\n",
        "***Note:*** ***Adjust parameters in the Settings cell (you will need an [Edge Impulse](https://www.edgeimpulse.com/) account)***\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***P.S: Since I've already included the TensorFlow Lite model to the main project, running this colab is not required. You don't need to retrain the model and go through all the steps again.***"
      ],
      "metadata": {
        "id": "Zb7HFZ7SGLem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 1 : Update Node.js to the latest stable version***"
      ],
      "metadata": {
        "id": "8bUetido-rhW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81cDNtYQj-ao"
      },
      "source": [
        "!npm cache clean -f\n",
        "!npm install -g n\n",
        "!n 16.18.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 2 : Install required packages and tools***"
      ],
      "metadata": {
        "id": "YYNg27aC-0gB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMjn7Y0iPXCh"
      },
      "source": [
        "!python -m pip install soundfile\n",
        "!npm install -g --unsafe-perm edge-impulse-cli"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 3: Settings***"
      ],
      "metadata": {
        "id": "ADxd1NZf-6oY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c06YDTU0c0-H"
      },
      "source": [
        "### Settings (do not need to change these)\n",
        "BASE_DIR = \"/content\"\n",
        "OUT_DIR = \"keywords_curated\"\n",
        "GOOGLE_DATASET_FILENAME = \"speech_commands_v0.02.tar.gz\"\n",
        "GOOGLE_DATASET_URL = \"http://download.tensorflow.org/data/\" + GOOGLE_DATASET_FILENAME\n",
        "GOOGLE_DATASET_DIR = \"google_speech_commands\"\n",
        "CURATION_SCRIPT = \"dataset-curation.py\"\n",
        "CURATION_SCRIPT_URL = \"https://raw.githubusercontent.com/Ashish0-0/NeuroKey-Embedded/main/\" + CURATION_SCRIPT\n",
        "UTILS_SCRIPT_URL = \"https://raw.githubusercontent.com/Ashish0-0/NeuroKey-Embedded/main/utils.py\"\n",
        "NUM_SAMPLES = 1500    # Target number of samples to mix and send to Edge Impulse\n",
        "WORD_VOL = 1.0        # Relative volume of word in output sample\n",
        "BG_VOL = 0.1          # Relative volume of noise in output sample\n",
        "SAMPLE_TIME = 1.0     # Time (seconds) of output sample\n",
        "SAMPLE_RATE = 16000   # Sample rate (Hz) of output sample\n",
        "BIT_DEPTH = \"PCM_16\"  # Options: [PCM_16, PCM_24, PCM_32, PCM_U8, FLOAT, DOUBLE]\n",
        "BG_DIR = \"_background_noise_\"\n",
        "TEST_RATIO = 0.2      # 20% reserved for test set, rest is for training\n",
        "EI_INGEST_TEST_URL = \"https://ingestion.edgeimpulse.com/api/test/data\"\n",
        "EI_INGEST_TRAIN_URL = \"https://ingestion.edgeimpulse.com/api/training/data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 4 : Download Google Speech Commands Dataset***"
      ],
      "metadata": {
        "id": "xKZ14mAFDoZR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVA3SDiQd-jh"
      },
      "source": [
        "!cd {BASE_DIR}\n",
        "!wget {GOOGLE_DATASET_URL}\n",
        "!mkdir {GOOGLE_DATASET_DIR}\n",
        "!echo \"Extracting...\"\n",
        "!tar xfz {GOOGLE_DATASET_FILENAME} -C {GOOGLE_DATASET_DIR}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNGNSwX_d_-E"
      },
      "source": [
        "### Pull out background noise directory\n",
        "!cd {BASE_DIR}\n",
        "!mv \"{GOOGLE_DATASET_DIR}/{BG_DIR}\" \"{BG_DIR}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 5 : Add the API key***"
      ],
      "metadata": {
        "id": "OYezRqkgFAN1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nDT4lYEMlY1"
      },
      "source": [
        "# Note: It is necessary to add your api key below in the EI_API_KEY\n",
        "\n",
        "# Edge Impulse > your_project > Dashboard > Keys\n",
        "EI_API_KEY = \"ei_e544...\" # Replace with your API key\n",
        "\n",
        "# Recommended: use 2 keywords for microcontroller demo becuase we dont have space for more keywords, for that we need to use a microcontroller with more storage.\n",
        "TARGETS = \"yes, no\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 6 : Download curation and utils scripts***"
      ],
      "metadata": {
        "id": "9XfZpt7FFLnL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ve08zgfVLem"
      },
      "source": [
        "!wget {CURATION_SCRIPT_URL}\n",
        "!wget {UTILS_SCRIPT_URL}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 7 : Perform curation and mixing of samples with background noise***"
      ],
      "metadata": {
        "id": "tYSoaTpuFhV6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O-M_hViZ0ew"
      },
      "source": [
        "!cd {BASE_DIR}\n",
        "!python {CURATION_SCRIPT} \\\n",
        "  -t \"{TARGETS}\" \\\n",
        "  -n {NUM_SAMPLES} \\\n",
        "  -w {WORD_VOL} \\\n",
        "  -g {BG_VOL} \\\n",
        "  -s {SAMPLE_TIME} \\\n",
        "  -r {SAMPLE_RATE} \\\n",
        "  -e {BIT_DEPTH} \\\n",
        "  -b \"{BG_DIR}\" \\\n",
        "  -o \"{OUT_DIR}\" \\\n",
        "  \"{GOOGLE_DATASET_DIR}\" \\\n",
        "  \"{CUSTOM_DATASET_PATH}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 8 : Use CLI tool to send curated dataset to Edge Impulse***"
      ],
      "metadata": {
        "id": "1Oczk63vFm-A"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXd0wH1-hEEX"
      },
      "source": [
        "!cd {BASE_DIR}\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Seed with system time\n",
        "random.seed()\n",
        "\n",
        "# Go through each category in our curated dataset\n",
        "for dir in os.listdir(OUT_DIR):\n",
        "\n",
        "  # Create list of files for one category\n",
        "  paths = []\n",
        "  for filename in os.listdir(os.path.join(OUT_DIR, dir)):\n",
        "    paths.append(os.path.join(OUT_DIR, dir, filename))\n",
        "\n",
        "  # Shuffle and divide into test and training sets\n",
        "  random.shuffle(paths)\n",
        "  num_test_samples = int(TEST_RATIO * len(paths))\n",
        "  test_paths = paths[:num_test_samples]\n",
        "  train_paths = paths[num_test_samples:]\n",
        "\n",
        "  # Create arugments list (as a string) for CLI call\n",
        "  test_paths = ['\"' + s + '\"' for s in test_paths]\n",
        "  test_paths = ' '.join(test_paths)\n",
        "  train_paths = ['\"' + s + '\"' for s in train_paths]\n",
        "  train_paths = ' '.join(train_paths)\n",
        "\n",
        "  # Send test files to Edge Impulse\n",
        "  !edge-impulse-uploader \\\n",
        "    --category testing \\\n",
        "    --label {dir} \\\n",
        "    --api-key {EI_API_KEY} \\\n",
        "    --silent \\\n",
        "    {test_paths}\n",
        "\n",
        "  # # Send training files to Edge Impulse\n",
        "  !edge-impulse-uploader \\\n",
        "    --category training \\\n",
        "    --label {dir} \\\n",
        "    --api-key {EI_API_KEY} \\\n",
        "    --silent \\\n",
        "    {train_paths}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}